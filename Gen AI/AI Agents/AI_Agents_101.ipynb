{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# AI Agents 101\n",
    "\n",
    "In this notebook we will explore AI Agents using Langchain\n",
    "\n",
    "Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.\n",
    "\n",
    "To learn more about Jupyter Notebooks in PyCharm, see [help](https://www.jetbrains.com/help/pycharm/ipython-notebook-support.html).\n",
    "For an overview of PyCharm, go to Help -> Learn IDE features or refer to [our documentation](https://www.jetbrains.com/help/pycharm/getting-started.html)."
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Installations\n",
    "- Langchain\n",
    "- Langchain-groq\n",
    "- python-dotenv"
   ],
   "id": "2a74eb5557e4b906"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T15:27:28.032975Z",
     "start_time": "2025-11-24T15:26:58.878554Z"
    }
   },
   "cell_type": "code",
   "source": "! pip install langchain",
   "id": "fbc121e30a2defb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-1.0.8-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting langchain-core<2.0.0,>=1.0.6 (from langchain)\n",
      "  Downloading langchain_core-1.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting langgraph<1.1.0,>=1.0.2 (from langchain)\n",
      "  Downloading langgraph-1.0.3-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Downloading pydantic-2.12.4-py3-none-any.whl.metadata (89 kB)\n",
      "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core<2.0.0,>=1.0.6->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core<2.0.0,>=1.0.6->langchain)\n",
      "  Downloading langsmith-0.4.46-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.6->langchain) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.6->langchain) (6.0.3)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<2.0.0,>=1.0.6->langchain)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.6->langchain) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.6->langchain) (3.0.0)\n",
      "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Downloading langgraph_checkpoint-3.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Downloading langgraph_prebuilt-1.0.5-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting xxhash>=3.5.0 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Downloading xxhash-3.6.0-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
      "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Downloading ormsgpack-1.12.0-cp313-cp313-win_amd64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Collecting orjson>=3.10.1 (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Downloading orjson-3.11.4-cp313-cp313-win_amd64.whl.metadata (42 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.6->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.6->langchain) (2.32.5)\n",
      "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.6->langchain)\n",
      "  Downloading zstandard-0.25.0-cp313-cp313-win_amd64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.41.5-cp313-cp313-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.6->langchain) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.6->langchain) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.3.1)\n",
      "Downloading langchain-1.0.8-py3-none-any.whl (93 kB)\n",
      "Downloading langchain_core-1.1.0-py3-none-any.whl (473 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langgraph-1.0.3-py3-none-any.whl (156 kB)\n",
      "Downloading langgraph_checkpoint-3.0.1-py3-none-any.whl (46 kB)\n",
      "Downloading langgraph_prebuilt-1.0.5-py3-none-any.whl (35 kB)\n",
      "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
      "Downloading langsmith-0.4.46-py3-none-any.whl (411 kB)\n",
      "Downloading pydantic-2.12.4-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp313-cp313-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 12.4 MB/s eta 0:00:00\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading orjson-3.11.4-cp313-cp313-win_amd64.whl (131 kB)\n",
      "Downloading ormsgpack-1.12.0-cp313-cp313-win_amd64.whl (112 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading xxhash-3.6.0-cp313-cp313-win_amd64.whl (31 kB)\n",
      "Downloading zstandard-0.25.0-cp313-cp313-win_amd64.whl (506 kB)\n",
      "Installing collected packages: zstandard, xxhash, typing-inspection, tenacity, pydantic-core, ormsgpack, orjson, jsonpatch, annotated-types, requests-toolbelt, pydantic, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langgraph-prebuilt, langgraph, langchain\n",
      "\n",
      "   -- -------------------------------------  1/18 [xxhash]\n",
      "   ------ ---------------------------------  3/18 [tenacity]\n",
      "   ------ ---------------------------------  3/18 [tenacity]\n",
      "   -------- -------------------------------  4/18 [pydantic-core]\n",
      "   ----------- ----------------------------  5/18 [ormsgpack]\n",
      "   --------------- ------------------------  7/18 [jsonpatch]\n",
      "   ----------------- ----------------------  8/18 [annotated-types]\n",
      "   -------------------- -------------------  9/18 [requests-toolbelt]\n",
      "   -------------------- -------------------  9/18 [requests-toolbelt]\n",
      "   -------------------- -------------------  9/18 [requests-toolbelt]\n",
      "   -------------------- -------------------  9/18 [requests-toolbelt]\n",
      "   ---------------------- ----------------- 10/18 [pydantic]\n",
      "   ---------------------- ----------------- 10/18 [pydantic]\n",
      "   ---------------------- ----------------- 10/18 [pydantic]\n",
      "   ---------------------- ----------------- 10/18 [pydantic]\n",
      "   ---------------------- ----------------- 10/18 [pydantic]\n",
      "   ---------------------- ----------------- 10/18 [pydantic]\n",
      "   ---------------------- ----------------- 10/18 [pydantic]\n",
      "   ---------------------- ----------------- 10/18 [pydantic]\n",
      "   ---------------------- ----------------- 10/18 [pydantic]\n",
      "   ---------------------- ----------------- 10/18 [pydantic]\n",
      "   ---------------------- ----------------- 10/18 [pydantic]\n",
      "   ---------------------- ----------------- 10/18 [pydantic]\n",
      "   ---------------------- ----------------- 10/18 [pydantic]\n",
      "   ---------------------- ----------------- 10/18 [pydantic]\n",
      "   ---------------------- ----------------- 10/18 [pydantic]\n",
      "   ---------------------- ----------------- 10/18 [pydantic]\n",
      "   ---------------------- ----------------- 10/18 [pydantic]\n",
      "   ---------------------- ----------------- 10/18 [pydantic]\n",
      "   ---------------------- ----------------- 10/18 [pydantic]\n",
      "   ---------------------- ----------------- 10/18 [pydantic]\n",
      "   ------------------------ --------------- 11/18 [langsmith]\n",
      "   ------------------------ --------------- 11/18 [langsmith]\n",
      "   ------------------------ --------------- 11/18 [langsmith]\n",
      "   ------------------------ --------------- 11/18 [langsmith]\n",
      "   ------------------------ --------------- 11/18 [langsmith]\n",
      "   ------------------------ --------------- 11/18 [langsmith]\n",
      "   ------------------------ --------------- 11/18 [langsmith]\n",
      "   ------------------------ --------------- 11/18 [langsmith]\n",
      "   ------------------------ --------------- 11/18 [langsmith]\n",
      "   ------------------------ --------------- 11/18 [langsmith]\n",
      "   ------------------------ --------------- 11/18 [langsmith]\n",
      "   -------------------------- ------------- 12/18 [langgraph-sdk]\n",
      "   -------------------------- ------------- 12/18 [langgraph-sdk]\n",
      "   ---------------------------- ----------- 13/18 [langchain-core]\n",
      "   ---------------------------- ----------- 13/18 [langchain-core]\n",
      "   ---------------------------- ----------- 13/18 [langchain-core]\n",
      "   ---------------------------- ----------- 13/18 [langchain-core]\n",
      "   ---------------------------- ----------- 13/18 [langchain-core]\n",
      "   ---------------------------- ----------- 13/18 [langchain-core]\n",
      "   ---------------------------- ----------- 13/18 [langchain-core]\n",
      "   ---------------------------- ----------- 13/18 [langchain-core]\n",
      "   ---------------------------- ----------- 13/18 [langchain-core]\n",
      "   ---------------------------- ----------- 13/18 [langchain-core]\n",
      "   ---------------------------- ----------- 13/18 [langchain-core]\n",
      "   ---------------------------- ----------- 13/18 [langchain-core]\n",
      "   ---------------------------- ----------- 13/18 [langchain-core]\n",
      "   ---------------------------- ----------- 13/18 [langchain-core]\n",
      "   ---------------------------- ----------- 13/18 [langchain-core]\n",
      "   ---------------------------- ----------- 13/18 [langchain-core]\n",
      "   ---------------------------- ----------- 13/18 [langchain-core]\n",
      "   ---------------------------- ----------- 13/18 [langchain-core]\n",
      "   ---------------------------- ----------- 13/18 [langchain-core]\n",
      "   ---------------------------- ----------- 13/18 [langchain-core]\n",
      "   ---------------------------- ----------- 13/18 [langchain-core]\n",
      "   ---------------------------- ----------- 13/18 [langchain-core]\n",
      "   ---------------------------- ----------- 13/18 [langchain-core]\n",
      "   ---------------------------- ----------- 13/18 [langchain-core]\n",
      "   ---------------------------- ----------- 13/18 [langchain-core]\n",
      "   ---------------------------- ----------- 13/18 [langchain-core]\n",
      "   ---------------------------- ----------- 13/18 [langchain-core]\n",
      "   ---------------------------- ----------- 13/18 [langchain-core]\n",
      "   ---------------------------- ----------- 13/18 [langchain-core]\n",
      "   ------------------------------- -------- 14/18 [langgraph-checkpoint]\n",
      "   ------------------------------- -------- 14/18 [langgraph-checkpoint]\n",
      "   ------------------------------- -------- 14/18 [langgraph-checkpoint]\n",
      "   --------------------------------- ------ 15/18 [langgraph-prebuilt]\n",
      "   ----------------------------------- ---- 16/18 [langgraph]\n",
      "   ----------------------------------- ---- 16/18 [langgraph]\n",
      "   ----------------------------------- ---- 16/18 [langgraph]\n",
      "   ----------------------------------- ---- 16/18 [langgraph]\n",
      "   ----------------------------------- ---- 16/18 [langgraph]\n",
      "   ----------------------------------- ---- 16/18 [langgraph]\n",
      "   ----------------------------------- ---- 16/18 [langgraph]\n",
      "   ----------------------------------- ---- 16/18 [langgraph]\n",
      "   ----------------------------------- ---- 16/18 [langgraph]\n",
      "   ----------------------------------- ---- 16/18 [langgraph]\n",
      "   ------------------------------------- -- 17/18 [langchain]\n",
      "   ------------------------------------- -- 17/18 [langchain]\n",
      "   ------------------------------------- -- 17/18 [langchain]\n",
      "   ------------------------------------- -- 17/18 [langchain]\n",
      "   ------------------------------------- -- 17/18 [langchain]\n",
      "   ------------------------------------- -- 17/18 [langchain]\n",
      "   ---------------------------------------- 18/18 [langchain]\n",
      "\n",
      "Successfully installed annotated-types-0.7.0 jsonpatch-1.33 langchain-1.0.8 langchain-core-1.1.0 langgraph-1.0.3 langgraph-checkpoint-3.0.1 langgraph-prebuilt-1.0.5 langgraph-sdk-0.2.9 langsmith-0.4.46 orjson-3.11.4 ormsgpack-1.12.0 pydantic-2.12.4 pydantic-core-2.41.5 requests-toolbelt-1.0.0 tenacity-9.1.2 typing-inspection-0.4.2 xxhash-3.6.0 zstandard-0.25.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T17:34:38.322746Z",
     "start_time": "2025-11-24T17:34:31.491686Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install langchain-groq",
   "id": "267908654ee0d07f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-groq\n",
      "  Downloading langchain_groq-1.1.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting groq<1.0.0,>=0.30.0 (from langchain-groq)\n",
      "  Downloading groq-0.36.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from langchain-groq) (1.1.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (4.11.0)\n",
      "Collecting distro<2,>=1.7.0 (from groq<1.0.0,>=0.30.0->langchain-groq)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (2.12.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1.0.0,>=0.30.0->langchain-groq) (3.11)\n",
      "Requirement already satisfied: certifi in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (0.16.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-groq) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-groq) (0.4.46)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-groq) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-groq) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-groq) (9.1.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain-groq) (3.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-groq) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-groq) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-groq) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-groq) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1.0.0,>=0.30.0->langchain-groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1.0.0,>=0.30.0->langchain-groq) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1.0.0,>=0.30.0->langchain-groq) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-groq) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gjrah\\pycharmmiscproject\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-groq) (2.5.0)\n",
      "Downloading langchain_groq-1.1.0-py3-none-any.whl (19 kB)\n",
      "Downloading groq-0.36.0-py3-none-any.whl (137 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: distro, groq, langchain-groq\n",
      "\n",
      "   ------------- -------------------------- 1/3 [groq]\n",
      "   ------------- -------------------------- 1/3 [groq]\n",
      "   ------------- -------------------------- 1/3 [groq]\n",
      "   ------------- -------------------------- 1/3 [groq]\n",
      "   ---------------------------------------- 3/3 [langchain-groq]\n",
      "\n",
      "Successfully installed distro-1.9.0 groq-0.36.0 langchain-groq-1.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T17:36:45.575882Z",
     "start_time": "2025-11-24T17:36:40.187433Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install python-dotenv",
   "id": "949a68871f8f6105",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Setting up Environment Variables",
   "id": "19c45780934392e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T08:33:46.268562Z",
     "start_time": "2025-11-25T08:33:46.130156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os #Importing os to access the file\n",
    "from dotenv import load_dotenv #importing dotenv to load the .env file\n",
    "\n",
    "load_dotenv(dotenv_path = \".env\")\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")"
   ],
   "id": "41e1fbaa765be756",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T08:33:46.759904Z",
     "start_time": "2025-11-25T08:33:46.581111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#langchain import to create agents\n",
    "from langchain.agents import create_agent"
   ],
   "id": "13899985e8fc7f1a",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T19:04:32.650161Z",
     "start_time": "2025-11-24T19:04:32.645989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Define a tool for the agent to call\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n"
   ],
   "id": "2680861be25cd39b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T15:02:43.553546Z",
     "start_time": "2025-11-25T15:02:41.106492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#langchain import to define our chat model\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\n",
    "    \"qwen/qwen3-32b\", #model\n",
    "    model_provider=\"groq\", #model provider\n",
    "    temperature = 0 #temperature\n",
    ")"
   ],
   "id": "c3ed54e7ca68c487",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Mini Documentation\n",
    "- When you wrap a model with init_chat_model, you freeze these settings.\n",
    " This ensures your agent behaves the same way every time."
   ],
   "id": "693f8c0e690c7df9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T19:28:45.003181Z",
     "start_time": "2025-11-24T19:28:44.983711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Create an agent with an LLM model along with the tools and system prompt\n",
    "agent = create_agent(\n",
    "    model = model,\n",
    "    tools = [get_weather],\n",
    "    system_prompt=\"\"\"You are an weather analyst, you are responsible to identify if an given text is an question relevant to seeking information about weather. Always extract the city from a given query and pass it to the tool, fetch the response and generate the final response.\n",
    "    \"\"\"\n",
    ")"
   ],
   "id": "66dd64a32291b749",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T19:28:46.321231Z",
     "start_time": "2025-11-24T19:28:45.015253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Viewing the results\n",
    "agent.invoke(\n",
    "    {\n",
    "        \"messages\": [{\"role\":\"user\", \"content\": \"What's the weather in Chennai\"}]\n",
    "    }\n",
    ")"
   ],
   "id": "157588bbe00afb75",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"What's the weather in Chennai\", additional_kwargs={}, response_metadata={}, id='3c57d0de-7bd2-47a4-b765-cce99bf48677'),\n",
       "  AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, the user is asking, \"What\\'s the weather in Chennai?\" I need to determine if this is a weather-related question. The query clearly mentions \"weather\" and specifies the city \"Chennai.\" My task is to extract the city from the query and use the provided tool to get the weather information.\\n\\nFirst, I\\'ll check if the function get_weather is available. Yes, it is. The parameters required are the city, which in this case is Chennai. There\\'s no ambiguity here since the user directly mentioned the city. I don\\'t need to ask for clarification. \\n\\nNext, I should structure the tool call correctly. The function name is get_weather, and the argument should be a JSON object with the city key. So the tool call would be {\"name\": \"get_weather\", \"arguments\": {\"city\": \"Chennai\"}}. \\n\\nI need to make sure there are no typos in the city name. Chennai is correctly spelled. Once the tool fetches the data, I can present the weather details to the user. Since the user didn\\'t specify a particular aspect of the weather, providing a general overview would be appropriate. \\n\\nI should also consider if there are any other possible functions, but in this case, only get_weather is available. No need to involve other tools. Just proceed with the function call as instructed.\\n', 'tool_calls': [{'id': 'cbh677bss', 'function': {'arguments': '{\"city\":\"Chennai\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 297, 'prompt_tokens': 202, 'total_tokens': 499, 'completion_time': 0.543482505, 'completion_tokens_details': {'reasoning_tokens': 272}, 'prompt_time': 0.008856872, 'prompt_tokens_details': None, 'queue_time': 0.050858988, 'total_time': 0.552339377}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--e5b32515-dfe9-496b-84b0-36c8902cb7ff-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'Chennai'}, 'id': 'cbh677bss', 'type': 'tool_call'}], usage_metadata={'input_tokens': 202, 'output_tokens': 297, 'total_tokens': 499, 'output_token_details': {'reasoning': 272}}),\n",
       "  ToolMessage(content=\"It's always sunny in Chennai!\", name='get_weather', id='31fe7e37-7ca5-4afe-b0c6-5d89074a6ad2', tool_call_id='cbh677bss'),\n",
       "  AIMessage(content='The weather in Chennai is currently sunny! It seems like a pleasant day there. ðŸ˜Š', additional_kwargs={'reasoning_content': \"Okay, the user asked about the weather in Chennai. I called the get_weather function with Chennai as the city. The response came back saying it's always sunny there. Now I need to relay that information clearly.\\n\\nFirst, I should confirm the city they asked about. Then, present the weather information from the tool's response. Keep it straightforward and friendly. Maybe add a sentence about the weather being pleasant since it's sunny. Make sure there's no markdown and the response is natural.\\n\"}, response_metadata={'token_usage': {'completion_tokens': 121, 'prompt_tokens': 242, 'total_tokens': 363, 'completion_time': 0.252255616, 'completion_tokens_details': {'reasoning_tokens': 98}, 'prompt_time': 0.009448589, 'prompt_tokens_details': None, 'queue_time': 0.160247981, 'total_time': 0.261704205}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_2bfcc54d36', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--82babdb9-1605-4ca2-9dfc-6f27c7442b52-0', usage_metadata={'input_tokens': 242, 'output_tokens': 121, 'total_tokens': 363, 'output_token_details': {'reasoning': 98}})]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T19:28:47.424738Z",
     "start_time": "2025-11-24T19:28:46.335751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Storing the results\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [{\"role\":\"user\", \"content\":\"What's the weather in Chennai\"}]\n",
    "    }\n",
    ")"
   ],
   "id": "594f12d6a7daed5f",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T19:28:47.444768Z",
     "start_time": "2025-11-24T19:28:47.439270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Printing only the end results\n",
    "print(result.get(\"messages\")[-1].content)"
   ],
   "id": "b87e94362962fc75",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather in Chennai is currently sunny! It seems like a pleasant day there. ðŸ˜Š\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Predictable AI Agent\n",
    "- Predictable AI Agents are AI agents that do not guess anything.\n",
    " - If it needs information, it must call the correct tool.\n",
    " - This makes the system predictable and safe.\n",
    "\n",
    "### Mini Documentation\n",
    "- We use tool to define a function as tool in langchain, so the langchain orchestration understands with function is tool, which isn't.\n",
    "- ToolRuntime is used modify tool's data access during agent's Runtime.\n",
    "- Tool Strategy defines how the agent output should be."
   ],
   "id": "f31992e3bdfac345"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T15:14:35.869714Z",
     "start_time": "2025-11-25T15:14:35.825810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataclasses import dataclass\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langchain.agents.structured_output import ToolStrategy"
   ],
   "id": "a6ffb43e35dc05e0",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T15:12:51.618436Z",
     "start_time": "2025-11-25T15:12:51.524139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#We are defining weather tool for our agent\n",
    "\n",
    "@tool\n",
    "def get_weather_for_location(city: str) -> str:\n",
    "    \"\"\"\n",
    "    A simple tool that refers weather information.\n",
    "    In a real system, this could call a weather API.\n",
    "    \"\"\"\n",
    "    return f\"It's summy in {city}\""
   ],
   "id": "7c49ef3311ebb90e",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T10:41:04.981341Z",
     "start_time": "2025-11-25T10:41:04.965317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "    This class acts like the context to agent, where if user_id is passed in,\n",
    "    it personalizes for the user, this is useful when the agents are connected\n",
    "    to databases or APIs.\n",
    "\"\"\"\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    user_id: str"
   ],
   "id": "ebbdd9bdd46d36f7",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T14:31:34.453687Z",
     "start_time": "2025-11-25T14:31:34.063298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@tool\n",
    "def get_user_location(runtime: ToolRuntime[Context]) -> str:\n",
    "    \"\"\"\n",
    "    A context-aware tool.\n",
    "    It reads the user_id from runtime.context and returns the user's locations.\n",
    "\n",
    "    In real world, you can replace this with a real database or user profile lookup.\n",
    "    \"\"\"\n",
    "\n",
    "    user_id = runtime.context.user_id\n",
    "    return \"Florida\" if user_id == \"1\" else \"Banglore\"\n"
   ],
   "id": "d86e8b8e91fe0740",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Mini Documentation\n",
    "- The first tool is straightforward: the agent calls it when it already knows the city.\n",
    "\n",
    "- The second tool is the interesting part. Instead of taking direct arguments, it receives a runtime object."
   ],
   "id": "5f9da4e165af4b23"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T14:51:22.323572Z",
     "start_time": "2025-11-25T14:51:22.309866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Defining response structure while Langchain maintains it's output structure\n",
    "@dataclass\n",
    "class ResponseFormat:\n",
    "    punny_response: str\n",
    "    weather_conditions: str | None = None"
   ],
   "id": "f640a5dd4a1dca73",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T14:58:29.545692Z",
     "start_time": "2025-11-25T14:58:29.401406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "#Simple In-Memory Storage for conversation history\n",
    "checkpointer = InMemorySaver()"
   ],
   "id": "90d8b29c3713ad12",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T15:01:39.198832Z",
     "start_time": "2025-11-25T15:01:39.185586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# System Prompt\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are an expert weather forecaster, who speaks in puns. You have access to two tools:\n",
    "- get_weather_for_location: use this to get the weather for a specific location\n",
    "- get_user_location: use this to get the user's location\n",
    "If a user asks you for the weather, make sure you know the location. If you can tell from the question that they mean wherever they are, use the get_user_location tool to find their location.\n",
    "\"\"\""
   ],
   "id": "fc58bf37084e8868",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T15:15:02.185625Z",
     "start_time": "2025-11-25T15:15:01.964339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "agent = create_agent(\n",
    "    model = model, #model\n",
    "    system_prompt=SYSTEM_PROMPT, #System Prompt\n",
    "    tools=[get_user_location,get_weather_for_location], #Tools defined\n",
    "    context_schema=Context, #Context we have defined\n",
    "    response_format=ToolStrategy(ResponseFormat), #As the name suggests,it's context format\n",
    "    checkpointer=checkpointer #checkpointer for memory\n",
    ")"
   ],
   "id": "b582493e2123b38",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Thread ID groups all messages into a single session.\n",
    "# Reusing the same ID lets the agent remember context.\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\":\"1\"}}"
   ],
   "id": "ac52ed3212273fa0",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T15:22:11.779408Z",
     "start_time": "2025-11-25T15:22:06.318233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Trail Output #1\n",
    "\"\"\"\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\n",
    "        \"messages\":[{\"role\":\"user\", \"content\":\"What is the weather outside ?\"}]\n",
    "    },\n",
    "    config = config,\n",
    "    context=Context(user_id=\"1\")\n",
    ")"
   ],
   "id": "60f564384d3475a6",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T15:23:45.518431Z",
     "start_time": "2025-11-25T15:23:45.511451Z"
    }
   },
   "cell_type": "code",
   "source": "print(response['structured_response'])",
   "id": "ddc4edc56ff1a2d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponseFormat(punny_response=\"It's a 'sun' day in Florida!\", weather_conditions='summy')\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T15:31:37.773168Z",
     "start_time": "2025-11-25T15:31:35.020660Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Trail Output #2\n",
    "\"\"\"\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\n",
    "        \"messages\":[{\"role\":\"user\", \"content\":\"What did I last asked you about ?\"}]\n",
    "    },\n",
    "    config = config,\n",
    "    context=Context(user_id=\"1\")\n",
    ")"
   ],
   "id": "49cb1b9842135272",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T15:31:49.615089Z",
     "start_time": "2025-11-25T15:31:49.605275Z"
    }
   },
   "cell_type": "code",
   "source": "print(response[\"structured_response\"])",
   "id": "f76f31578beaaaee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponseFormat(punny_response='Sunny days and forgetful minds! You asked about the weather in Florida.', weather_conditions=None)\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2365a1ed9a8b6cd5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
